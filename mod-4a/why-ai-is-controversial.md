---
title: AI Hype and AI Harms
layout: default
parent: Artificial Intelligence
nav_order: 4
---

# AI Hype and AI Harms

## AI Hype

We've seen that machine learning has produced tremendous advances in the ability of computers to detect and replicate pattens, solve complex problems, and generate new content from existing content using a combination of logic and probability. These advances are real.

We've also seen that these abilities have emerged from a computer science research program that began more than half a century ago with an ambitious overarching goal: to simulate human intelligence in a machine.

Finally, we'e seen that from the beginning, this program was one where talk of *simulating* intelligence easily slid over into talk of *creating* intelligence. "AI hype" might be said to begin with the obfuscation of the difference between these two things.

For businesses that sell AI systems, the financial incentives to keep up this obfuscation are obvious. The obfuscation also benefits businesses that invest in AI services with the thought that these might replace some of their actual human workers. 

But even when the sellers and buyers of AI services don't claim that the machines providing them actually *are* intelligent in the same way humans are, it benefits them to hype what the machines are actually capable of doing, and to minimize their failures&mdash;such as their well-documented propensity to generate non-existent facts and sources. (As is often noted, the now common term for this propensity, "hallucination," perpetuates the obfuscation described above by ascribing some kind of imaginative power to circuits and software.)

In their book *The AI Con: How to Fight Big Tech's Hype and Create the Future We Want*, computational linguist Emily M. Bender and sociologist Alex Hanna write,

> To put it bluntly, "AI" is a marketing term. It doesn't refer to a coherent set of technologies. Instead, the phrase "artificial intelligence" is deployed when the people building or selling a particular set of technologies will profit from getting others to believe that the technology is similar to humans, able to do things that, in fact, intrinsically require human judgment, perception, or creativity. (p. 38)

They continue,

> The set of technologies that get sold as AI is diverse, in both application and contruction&mdash;in fact, we wouldn't be surprised if some of the tech being sold this way is actually just a fancy wrapper around some spreadsheets. The term serves to obscure that diversity, however, so the conversation becomes clearer if one speaks in terms of "automation" rather than "AI" and looks at precisely *what is being automated.* (p. 39)

Bender and Hanna distinguish five types of automation among the systems marketed as powered by AI. Their point, again, is that these technologies don't all work the same way:

- *Decision-making:* Automated decision-making systems may be used, for example, to set bail, approve loans, review résumés, or determine eligibility for certain social benefits.
- *Classification:* Automated classification systems work on data to match patterns and assign the data to different categories. Facial recognition tools based on image databases and targeted advertising based on user data fall into this category.
- *Recommendation:* Automated recommendation systems lie behind the organization of social media feeds (when these are determined by a platform's algorithm) and suggestions from services like Netflix or Spotify. They generate recommendations based on a profile compiled from the user's data or from a similar user's profile.
- *Transcription/translation*: These automated systems translate information from one format to another. Examples include transforming speech into text, extracting text from images, and translating one language to another.
- *Text and image generation*: Also known, as we saw earlier, as "generative artificial intelligence" or "GenAI," automated text/image generation systems take a user prompt as input and generate plausible output in response.

Some of these technologies have been around for a long time; only recently, Bender and Hanna point out, have most of them been marketed under the banner of "AI."

All of these technologies can save time and produce other benefits in personal, business, or research contexts. It isn't hype to recognize what they can do. AI hype consists in exaggerating what they can do or in ignoring or minimizing the costs they incur&mdash;costs like those taken up below under "AI Harms."

Or, as Bender and Hanna arguing, in making them out to be, collectively, more than the sum of their parts&mdash;particularly in suggesting that together they put us into, or on the cusp of, a new era in which machines will somewhow awake into consciousness.

<!-- one last return to the original argument; bring Searle in here. -->



<!-- Bender et al, then MIT hype index (or reverse that order?) -->

<!-- together with the failure to mention that even when the output of AI systems seems remarkably human, that output is produced by processes quite different from those that produce the output of human thought.-->




<!-- taking advantage of fact that consciousness remains a mystery -->


<!-- # Why AI is Controversial

The practical and social issues raised by artificial intelligence are as thorny as the technology is complicated. Here are just a few of the concerns that have generated widespread and lively discussion:

- AI tools replicate and thereby amplify the biases and misinformation in the data they're trained on.
- AI tools can't distinguish fact from falsehood and frequently invent their own "facts" (a phenomenon sometimes called "hallucination.").
- Because AI tools solve problems through statistical inference, they can't be counted on to perform basic calculations or data analysis reliably.
- Much of the content used to train AI tools is copyrighted, raising questions about the legality of this training.
- AI tools have made it easier than ever to create and circulate misinformation and disinformation, polluting civic discourse and distorting the political process.
- AI tools for generating image content have led to new forms of sexual exploitation and harassment.
- AI tools have complicated the task of educators by making it harder to detect cheating.
- The data centers that make cloud-based AI tools available at scale consume large quantities of energy and water, resulting in significant potential for adverse effects on the environment and on the communities where these centers are located.
- To reduce the amount of toxic (e.g., racist, misogynistic, homophobic, transphobic, antisemitic, violent) content produced by the major AI tools available to the public, the companies that create them rely heavily on human labor that is typically poorly compensated.

The impact of AI on labor and the environment tends to receive less attention than the other concerns listed above.

This brief segment of the show *60 minutes* offers an introduction to the issue of poorly paid "humans in the loop":

<iframe width="560" height="315" src="https://www.youtube.com/embed/qZS50KXjAX0?si=2FwbWzCM1mTmaG5n" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

The first of several episodes in the series "Data Vampires" recorded for the podcast *Tech Won't Save Us* provides an introduction to the issues surrounding AI, the environment, and communities:

<iframe width="560" height="315" src="https://www.youtube.com/embed/ZPdzq1ZcBtw?si=dmclDATiMVBTMXVS" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe> -->