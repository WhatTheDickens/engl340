---
title: Responsible AI?
layout: default
parent: Artificial Intelligence
nav_order: 6
---

# Responsible AI?

Is it possible to get past [AI Hype]({{ site.url}}/mod-4a/ai-hype), mitigate [AI Harms]({{ site.url}}/mod-4a/ai-harms), and develop technologies of automation that are built and deployed responsibly?

What are the responsibilities of those who use these technologies?

The answer to the first question will likely depend on whether it's possible to enact and enforce laws and regulations that protect users, the general public, and the environment against the harms described earlier and any new harms that may emerge. The [Stanford Institute for Human-Centered AI (HAI)](https://hai.stanford.edu/) has developed an [index](https://hai.stanford.edu/ai-index/2025-ai-index-report/responsible-ai) that "explores RAI \[Responsible AI\] trends within key societal sectors—industry, academia, and policymaking—and analyzes specific subtopics, including privacy and data governance, fairness, transparency and explainability,
and security and safety, using benchmarks that illuminate model performance and highlights of notable research." The current iteration of the index makes it clear how much work remains to be done in this area.

It seems safe to say that no cultural consensus has emerged in answer to the second question, but here are a few guidelines worth considering, especially for academic users of AI:

- You should be transparent about any use you make of AI, including using a chatbot [as a writing companion](https://www.newyorker.com/culture/annals-of-inquiry/what-kind-of-writer-is-chatgpt)&mdash;to generate ideas, for example, or get feedback on a draft.
- You should never present the words generated by a chatbot as your own. Doing so may not consitute plagiarism (since you're not appropriating another *person's* work), but it's still, arguably, a kind of false representation.
- If you use a chatbot for research, you should independently verify every single fact and citation it serves up to you. "Hallucination" is still too common a feature of AI for the chatbot's output to be trustworthy.
- You should never supply to a chatbot, as input, content protected by copyright, unless expressly permitted, in writing, by the copyright holder.
- You should never supply to a chatbot someone else's personally identifiable information or any information legally regarded as confidential (such as an educational record).
